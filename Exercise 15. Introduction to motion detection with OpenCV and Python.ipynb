{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A Motion Detected Alarm System with Python and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we are going to develop – again! – a motion triggered alarm based on the frame differencing method. Now, we are going to do this using Python and OpenCV.\n",
    "\n",
    "Open Source Computer Vision Library (OpenCV) is a library written in C/C++ mainly aimed at real-time computer vision.\n",
    "\n",
    "OpenCV supports a wide variety of programming languages such as C++, Python, Java, etc. \n",
    "\n",
    "In particular, in this exercise we are going to introduce OpenCV-Python, a Python wrapper for the original OpenCV C++ implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach for developing this application is the same as proposed in Exercise 14:\n",
    "\n",
    "When the program starts, the program will capture from the webcam the ‘baseline’ image (see the left image below). This is the image without any 'intruder'. The program will keep capturing frames and comparing them with the baseline image. If no one enters the frame, nothing will happen. However, when somebody or something enters the frame (see the right image below), the program will detect that the captured frame and the baseline image are ‘very’ different and will trigger the audio alarm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alarm](../Images/Alarm_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very important: you need to run the code in your local machine for displaying the video and using the webcam.**\n",
    "\n",
    "**Exercise 1.1**: Download (or copy) this Jupyter notebook into your local machine.\n",
    "\n",
    "**Exercise 1.2**: Install the required Python libraries\n",
    "\n",
    "                pip install pyttsx3\n",
    "                pip install pywin32\n",
    "                pip install numpy\n",
    "                pip install opencv-python\n",
    "\n",
    "**Exercise 1.3**: Run and study the code *Capture and display the frames of a video with Python and OpenCV*.\n",
    "\n",
    "**Exercise 1.4**: Run and study the code *Capture and display webcam with Python and OpenCV*.\n",
    "\n",
    "**Exercise 1.5**: Run and study the code *Build a motion detected alarm system with Python*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3. Capture and display the frames of a video with Python and OpenCV.\n",
    "\n",
    " Run and study the code Capture and display the frames of a video with Python and OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture and display the frames of a video with Python and OpenCV\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Create a VideoCapture object and read the frames from an input file\n",
    "# You can download this video from https://www.loc.gov/item/00694162/ (or use another video!)\n",
    "video=cv2.VideoCapture('media-ammem-AmericaAtWorkAmericaAtLeisure-1968.mp4')\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if (video.isOpened()== False): \n",
    "  print(\"Error opening video file\")\n",
    "\n",
    "# # Read until video is completed or we press 'q'\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    # Note that VideoCapture captures the frames of a video without considering the fps of the video\n",
    "    check, frame = video.read()\n",
    "\n",
    "    if check == True:\n",
    "    \n",
    "        cv2.imshow(\"movie\",frame)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "# After the loop release the video object\n",
    "video.release()\n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4. Capture and display webcam with Python and OpenCV.\n",
    "\n",
    "Run and study the code Capture and display webcam with Python and OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture and display webcam with Python and OpenCV\n",
    "\n",
    "import cv2\n",
    "\n",
    "# We use VideoCapture function to create the video capture object\n",
    "# Note we put '0' to capture webcam\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "# We start an infinite loop and keep reading frames from the webcam until we press 'q'\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    cv2.imshow(\"Webcam\",frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# After the loop release the video object\n",
    "video.release()\n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5. Build a motion detected alarm system with Python.\n",
    "\n",
    "Run and study the code Build a motion detected alarm system with Python.\n",
    "\n",
    "In particular, analyse and try different parameters in the functions:\n",
    "\n",
    "- GaussianBlur(): for noise reduction (smoothening).\n",
    "- threshold(): you need to change the threshold function values for a better performance with your webcam , room's light, etc.\n",
    "- findContours(): this method identifies all the contours in an image. Experiment with the different contour retrieval modes (https://docs.opencv.org/4.5.2/d3/dc0/group__imgproc__shape.html#ga819779b9857cc2f8601e6526a3a5bc71) and contour approximation methods (https://docs.opencv.org/4.5.2/d3/dc0/group__imgproc__shape.html#ga4303f45752694956374734a03c54d5ff),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build A Motion Detected Alarm System with Python\n",
    "\n",
    "# let’s import the libraries\n",
    "# For playing the audio, we will be using “pyttsx3” python library to convert text to speech\n",
    "import cv2\n",
    "import pyttsx3\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "# This funtion plays the audio message\n",
    "def voice_alarm(alarm_sound):\n",
    "    alarm_sound.say(\"Intruder Detected\")\n",
    "    alarm_sound.runAndWait()\n",
    "    \n",
    "\n",
    "# Setting parameters for voice\n",
    "alarm_sound = pyttsx3.init()\n",
    "voices = alarm_sound.getProperty('voices')\n",
    "alarm_sound.setProperty('voice', voices[0].id)\n",
    "alarm_sound.setProperty('rate', 150)\n",
    "\n",
    "\n",
    "# The function to play the audio wil be executed in a separate thread.\n",
    "# So, there won't be lag in the video feed while the audio alert message is playing.\n",
    "alarm = threading.Thread(target=voice_alarm, args=(alarm_sound,))\n",
    "\n",
    "\n",
    "#status_list=[None,None]\n",
    "status_list=[0,0]\n",
    "initial_frame = None\n",
    "\n",
    "\n",
    "# We use VideoCapture function to create the video capture object\n",
    "video=cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# We start an infinite loop and keep reading frames from the webcam until we press 'q'\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    status=0\n",
    "\n",
    "    # Gray conversion and noise reduction (smoothening)\n",
    "    gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    blur_frame=cv2.GaussianBlur(gray_frame,(25,25),0)\n",
    "\n",
    "    \n",
    "    # The first captured frame is the baseline image\n",
    "    if initial_frame is None:\n",
    "        initial_frame = blur_frame\n",
    "        continue\n",
    "\n",
    "    # The difference between the baseline and the new frame\n",
    "    delta_frame=cv2.absdiff(initial_frame,blur_frame)\n",
    "    # The difference (the delta_frame) is converted into a binary image\n",
    "    # If a particular pixel value is greater than a certain threshold (specified by us here as 150),\n",
    "    # it will be assigned the value for White (255) else Black(0)\n",
    "    # Important: you may have to change the threshold value for a better performance with your webcam , room's light, etc.\n",
    "    threshold_frame=cv2.threshold(delta_frame,150,255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "\n",
    "    # The cv2.findContours() method we will identify all the contours in our image.\n",
    "    # This method expects 3 parameters, (a) image, (b) contour retrieval mode and\n",
    "    # (c) contour approximation method\n",
    "    (contours,_)=cv2.findContours(threshold_frame,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        # contourArea() method filters out any small contours\n",
    "        # You can change this value\n",
    "        if cv2.contourArea(c) < 1000:\n",
    "            continue\n",
    "        status=status + 1\n",
    "        (x, y, w, h)=cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 1)\n",
    "    status_list.append(status)\n",
    "\n",
    "\n",
    "    # The alarm is triggered if an 'intruder' is detected\n",
    "    # We can also trigger the alarm only if a moving object is detected with\n",
    "    #if status_list[-1]>= 1 and status_list[-2]==0:    \n",
    "    if status_list[-2]>= 1:\n",
    "        if (alarm.is_alive() == False):\n",
    "            alarm = threading.Thread(target=voice_alarm, args=(alarm_sound,))\n",
    "            alarm.start()\n",
    "\n",
    "        \n",
    "    # To better understand the application, we can visualise the different frames generated\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    cv2.imshow('Baseline image', initial_frame)\n",
    "    cv2.imshow(\"Gray Frame\",gray_frame)\n",
    "    cv2.imshow('Delta frame', delta_frame)   \n",
    "    cv2.imshow('Threshold frame', threshold_frame)\n",
    "    \n",
    "\n",
    "    # Stop the program by pressing 'q'    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "        \n",
    "# After the loop release the video object, stop the alarm\n",
    "# and destroy all the windows\n",
    "alarm_sound.stop()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This lab is based on https://github.com/arindomjit/Motion_Detected_Alarm by Arindomjit Bhattacharjee."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
